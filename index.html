<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }
    
    strong {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 24px;
    }
    
    papertitle {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    name {
      font-family: 'Galdeano', Verdana, Helvetica, sans-serif;
      font-size: 36px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      /* background-color: #ffffd0; */
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Elahe Vahdani</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Galdeano' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Elahe Vahdani</name>
              </p>
              <p>
                I'm a Ph.D. student in the <a href="http://media-lab.ccny.cuny.edu/wordpress/people/">Media Lab</a>, Dept. Computer Science at The City University of New York, advised by Professor <a href="http://media-lab.ccny.cuny.edu/wordpress/YLTCCNYHomepage/yltian.html">Ying-Li Tian</a>. 
                My current research focuses on Video Analysis including Action Recognition and Temporal Action Detection. I received my Bachelor's degree from Sharif University of Technology.    
		    
	      </p>
              <p align=center>
                <a href="mailto:evahdani@gradcenter.cuny.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=8UCruqIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="data/Elahe_Resume.pdf">Curriculum Vitae</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/elahe-vahdani-345675a8/"> LinkedIn </a>
              </p>
            </td>
            <td width="33%">
              <img src="images/eli1.jpeg" width="250px">
            </td>
          </tr>
        </table>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p>
                <strong>News:</strong>
                <br>
                <ul>
                  <li> Looking for summer 2021 internships, interested in Machine Learning, Computer Vision, and Data Analysis.</li>
		  <br>
		  <li> Received the MPhil degree (Master of Philosophy) in Computer  Science, The City University of New York.</li>
		  <br>
		  <li> Advanced to PhD candidacy.</li>  
<!-- 	          Title of the presentation: "Temporal Action Detection in Untrimmed Videos" -->
                </ul>
                <br>
              </p>
            </td>
          </tr>
        </table>

	
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
		<p>
                My research interests mainly lay in computer vision, machine learning, and image processing. Currently, I'm working on Action Recognition, and Temporal Action Detection tasks, and am interested in designing algorithms with limited supervision, such as self-supervised and weakly-supervised learning. I have also worked on Facial Expression Analysis, Cross-Modality Bridging and Vehicle Re-identification projects.
            Prior to that, my research was focused on Approximation Algorithms for NP-Hard problems.</span>
              </p>
            </td>
          </tr>
        </table>

	
	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		
            <tr onmouseout="ASL_cont_stop()" onmouseover="ASL_cont_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='ASL_cont_image'><img src='images/FE_figure.png' width="160px" height="160px"></div>
                <img src='images/FE_several.gif' width="160px" height="160px">
              </div>
              <script type="text/javascript">
                function ASL_cont_start() {
                  document.getElementById('ASL_cont_image').style.opacity = "1";
                }

                function ASL_cont_stop() {
                  document.getElementById('ASL_cont_image').style.opacity = "0";
                }
                ASL_cont_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/2005.00253.pdf">
                <papertitle>Recognizing American Sign Language Nonmanual Signal Grammar Errors in Continuous Videos</papertitle>
              </a>
              <br>
              <!-- <a href="http://timothybrooks.com/">Tim Brooks</a>, -->
       	      <strong>Elahe Vahdani*</strong>,
	      <a href="https://longlong-jing.github.io/">Longlong Jing*</a>,
              <a href="http://media-lab.ccny.cuny.edu/wordpress/YLTCCNYHomepage/yltian.html">Yingli Tian</a>,
              <a href="https://huenerfauth.ist.rit.edu/">Matt Huenerfaut</a>
              <br>
              <em>ICPR </em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2005.00253.pdf">PDF</a> 
              <p></p>
              <p> We designed an educational tool for sign language students to automatically process their signing videos and send them an immediate feedback regarding the fluency of their signing. The framework is based on deep-learning algorithms for temporal detection of grammatically important elements from continuous signing videos, and checking their correspondence in multiple modalities such as facial expression, head movements and hand gestures.</p>
            </td>
          </tr>

		
            <tr onmouseout="ASL_stop()" onmouseover="ASL_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id='ASL_image'><img src='images/sign-before.png' width="160px" height="160px"></div>
                <img src='images/ASL.gif' width="160px" height="160px">
              </div>
              <script type="text/javascript">
                function ASL_start() {
                  document.getElementById('ASL_image').style.opacity = "1";
                }

                function ASL_stop() {
                  document.getElementById('ASL_image').style.opacity = "0";
                }
                ASL_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="https://arxiv.org/pdf/1906.02851.pdf">
                <papertitle>Recognizing American Sign Language Manual Signs from RGB-D Videos</papertitle>
              </a>
              <br>
              <!-- <a href="http://timothybrooks.com/">Tim Brooks</a>, -->
              <a href="https://longlong-jing.github.io/">Longlong Jing*</a>,
       	      <strong>Elahe Vahdani*</strong>,
              <a href="http://media-lab.ccny.cuny.edu/wordpress/YLTCCNYHomepage/yltian.html">Yingli Tian</a>,
              <a href="https://huenerfauth.ist.rit.edu/">Matt Huenerfaut</a>
              <br>
              <em>Under Review </em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/1906.02851.pdf">PDF</a> /
	      <a href="https://longlong-jing.github.io/ASL-100-RGBD/">Project Page</a> /
	      <a href="https://nyu.databrary.org/volume/1062">Dataset</a> /
              <p></p>
              <p>We propose a 3D ConvNet based multi-stream framework to recognize American Sign Language (ASL) manual signs in real-time from RGB-D videos.</p>
            </td>
          </tr>

		
          <tr onmouseout="reid_stop()" onmouseover="reid_start()">
            <td width="25%">
              <div class="one">
                  <div class="two" id='reid_image'><img src='images/car-0.png' width="160px" height="160px"></div>
                <img src='images/vehicles.gif' width="160px" height="160px">
              </div>
              <script type="text/javascript">
                function reid_start() {
                  document.getElementById('reid_image').style.opacity = "1";
                }

                function reid_stop() {
                  document.getElementById('reid_image').style.opacity = "0";
                }
                reid_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Chen_Multi-camera_Vehicle_Tracking_and_Re-identification_on_AI_City_Challenge_2019_CVPRW_2019_paper.pdf">
                <papertitle>Multi-camera Vehicle Tracking and Re-identification on AI City Challenge 2019</papertitle>
              </a>
              <br>
              <a href="https://cyccty.github.io/">Yucheng Chen</a>,
              <a href="https://longlong-jing.github.io/">Longlong Jing</a>,
              <strong>Elahe Vahdani</strong>,
	      <a href="https://www.linkedin.com/in/ling-zhang-cs/">Ling Zhang</a>,
              <a href="http://dianzi.nwpu.edu.cn/info/1269/5955.htm">Mingyi He</a>,
              <a href="http://media-lab.ccny.cuny.edu/wordpress/YLTCCNYHomepage/yltian.html">Yingli Tian</a>              
              <br>
              <em>CVPR AI City Workshop</em>, 2019
              <br>
              <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Chen_Multi-camera_Vehicle_Tracking_and_Re-identification_on_AI_City_Challenge_2019_CVPRW_2019_paper.pdf">PDF</a> /
	      <a href="">Slides</a> /
	      <a href="data/cvpr19_poster_AICITY.pdf">Poster</a>
              <p></p>
              <p> Our solutions to the image-based vehicle re-identification track and multi-camera vehicle tracking track on AI City Challenge 2019 (AIC2019).  Our proposed
                  framework outperforms the current state-of-the-art vehicle ReID method by 16.3% on Veri dataset. </p>
            </td>
          </tr>

        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
